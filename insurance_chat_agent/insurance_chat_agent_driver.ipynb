{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c42927d-676f-4074-8840-b72eedfc303a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Building a multi-agent system with OpenAI Agents SDK on Databricks\n",
    "\n",
    "This notebook is the companion to the blog post [Building a multi-agent system with OpenAI Agents SDK on Databricks](https://medium.com/@AI-on-Databricks/building-a-multi-agent-system-with-openai-agents-sdk-on-databricks-6b6ad6774477)\n",
    "\n",
    "OpenAI recently released its own [Agents SDK](https://github.com/openai/openai-agents-python/tree/main) — it is a lightweight yet powerful framework for building multi-agent workflows.\n",
    "\n",
    "In this notebook, we demonstrate how to leverage the OpenAI Agents SDK and Databricks’ features to build and deploy an insurance-policy Q&A agent on the Databricks Data Intelligence Platform.\n",
    "\n",
    "\n",
    "**Note**:\n",
    "\n",
    "* The notebook is best to be run in a Unity Catalog enabled Databricks Workspace with serverless compute cluster\n",
    "* The example datasets are provided [here](https://github.com/qian-yu-db/OpenAI_Agents_SDK_on_Databricks/tree/main/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eee5885-fc37-4238-af34-172045c6f698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c52f607f-4477-4116-89f1-b6474c36b82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Pull your OpenAI API key from Databricks secrets\n",
    "my_scrept_scope = \"TO BE REPLACED\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=f\"my_secret_scope\", key=\"OpenAI\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set MLflow Experiment\n",
    "my_databricks_account = \"TO BE REPLACED\"\n",
    "mlflow.set_experiment(f\"/Users/{my_databricks_account}/ML_experiments/insurance_chat_agent\")\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a112b23-de81-4df6-baea-ea6927a0a8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set up UC Tools\n",
    "\n",
    "The key components of an Agentic system are LLM(s), Tools/knowledge Base(s), Orchastrator, and evaluation.\n",
    "\n",
    "![image](../imgs/multi-agent-workflow.webp)\n",
    "\n",
    "The UC tools can be convieniently created by using SQL syntax as below. We create the following UC functions for our AI insurance agent:\n",
    "\n",
    "- `search_claims_details_by_policy_no`: a SQL function that retrieves a customer’s claim history based on their policy number. Since it is governed by UC, it follows the 3-level namespace when defining the name of the UC function.\n",
    "- `policy_docs_vector_search`: a Databricks SQL AI Function that retrieves relevant document chunks from a Databricks Vector Search index using the approximate nearest neighbor (ANN) algorithm on an input query. Alternatively one can also define this tool using the Databricks AI Bridge `VectorSearchRetrieverTool`. See more details [`here`](https://docs.databricks.com/aws/en/generative-ai/agent-framework/unstructured-retrieval-tools).\n",
    "\n",
    "\n",
    "Please replace `catalog`, `schema` with your UC catalog and schema names.\n",
    "\n",
    "```sql\n",
    "-- Create a SQL function that searches for claims details by policy_no\n",
    "CREATE OR REPLACE FUNCTION catalog.schema.search_claims_details_by_policy_no (\n",
    "    input_policy_no STRING COMMENT 'Policy number'\n",
    ")\n",
    "RETURNS TABLE\n",
    "COMMENT 'Returns policy details about a customer given policy_no.'\n",
    "RETURN\n",
    "SELECT *\n",
    "FROM catalog.schema.claims_table\n",
    "WHERE policy_no = input_policy_no\n",
    ";\n",
    "\n",
    "-- Create a SQL function that calls the vector_search() AI Function\n",
    "CREATE OR REPLACE FUNCTION catalog.schema.policy_docs_vector_search (\n",
    "    query STRING\n",
    "    COMMENT 'The query string for searching insurance policy documentation.'\n",
    ")\n",
    "RETURNS TABLE\n",
    "COMMENT 'Executes a search on insurance policy documentation to retrieve text documents most relevant to the input query.'\n",
    "RETURN\n",
    "SELECT\n",
    "    chunked_text as page_content,\n",
    "    map('doc_path', path, 'chunk_id', chunk_id) as metadata\n",
    "FROM\n",
    "    vector_search(\n",
    "        index => catalog.schema.policy_docs_chunked_files_vs_index',\n",
    "        query => query,\n",
    "        num_results => 3\n",
    "    )\n",
    ";\n",
    "```\n",
    "\n",
    "To make UC functions work as tools with OpenAI Agents SDK, We uses [unity catalog OpenAI integration](https://github.com/unitycatalog/unitycatalog/tree/main/ai/integrations/openai) to perform UC function calls and they need to be wrapped under the `@function_tool` decorator.\n",
    "\n",
    "In addition, it supports Pydantic as a way to inject contexts into the agent, tool, or handoffs, or to enforce output type from an agent. Here we create a `UserInfo` class with a Pydantic base model with customer ID and policy number as arguments, which is used as context. The `conversation_id` and `user_id` are context parameters for MLflow `ChatAgent`, they are included so that we can log this workflow as a `ChatAgent` model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e10a620f-3a9f-48cc-b11c-bf88639207d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class UserInfo(BaseModel):\n",
    "    cust_id: str | None = None\n",
    "    policy_no: str | None = None\n",
    "    conversation_id: str | None = None\n",
    "    user_id: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2f6d653-5e34-4082-bc92-0a978c2bc6f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75592431-55fd-4758-a49d-d45600f69103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import (\n",
    "    DatabricksFunctionClient,\n",
    "    FunctionExecutionResult,\n",
    ")\n",
    "from agents import function_tool, RunContextWrapper\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def search_claims_details_by_policy_no(wrapper: RunContextWrapper[UserInfo], policy_no: str) -> FunctionExecutionResult:\n",
    "    print(\"[DEBUG]: the 'search_claims_details_by_policy_no' tool was called\")\n",
    "    wrapper.context.policy_no = policy_no\n",
    "    client = DatabricksFunctionClient()\n",
    "    return client.execute_function(\n",
    "        function_name=\"ai.insurance_agent.search_claims_details_by_policy_no\",\n",
    "        parameters={\"input_policy_no\": wrapper.context.policy_no},\n",
    "    )\n",
    "\n",
    "@function_tool\n",
    "def policy_docs_vector_search(query: str) -> FunctionExecutionResult:\n",
    "    print(\"[DEBUG]: the 'policy_docs_vector_search' tool was called\")\n",
    "    client = DatabricksFunctionClient()\n",
    "    return client.execute_function(\n",
    "        function_name=\"ai.insurance_agent.policy_docs_vector_search\",\n",
    "        parameters={\"query\": query},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2aadbbaa-bd69-418f-ad84-168f98c76337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Agents\n",
    "\n",
    "A multi-agent system is like a conversation between LLMs that work together to solve a problem, which requires “handing off” prompts, contexts, and outputs from one LLM (i.e. a single agent) to another.\n",
    "\n",
    "\n",
    "Here is a visualization of the multi-agent system\n",
    "\n",
    "![image](../imgs/insurance_chat_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5eeb872d-68f9-4f76-bfca-16565456ade5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If you want custom model hosted outside of OpenAI\n",
    "# You can use the following to set up\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel, set_tracing_disabled\n",
    "\n",
    "API_KEY = (\n",
    "    dbutils.notebook.entry_point.getDbutils()\n",
    "    .notebook()\n",
    "    .getContext()\n",
    "    .apiToken()\n",
    "    .getOrElse(None)\n",
    ")\n",
    "BASE_URL = (\n",
    "    f'https://{spark.conf.get(\"spark.databricks.workspaceUrl\")}/serving-endpoints'\n",
    ")\n",
    "\n",
    "# You can replace 'gtp-4o' with the MODEL variable in the Agent definition\n",
    "MODEL = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30020e68-cfff-4762-aa65-7c25104e7249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The instruction field is the prompt for the agent. We’ve added a `RECOMMENDED_PROMPT_PREFIX` object from OpenAI. This is a optional “hand-off” prompt, and we found it to work fairly well. The tools field is where you designate a list of tools that the agent can use to complete the task specified in the instruction. The model field is where you specify the LLM that powers the agent. It works natively with all OpenAI models, provided that you have access to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b76d845d-fb36-4d1d-80d2-2beb7d64cd6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "# This is OpenAI SDK's recommended prompt prefix\n",
    "RECOMMENDED_PROMPT_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13e9bd87-49ef-4163-b0d1-49cc9983c996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, set_tracing_disabled\n",
    "\n",
    "# You can turn off tracing by setting this to True\n",
    "set_tracing_disabled(disabled=False)\n",
    "\n",
    "claims_detail_retrieval_agent = Agent[UserInfo](\n",
    "    name=\"Claims Details Retrieval Agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are a claims details retrieval agent. \"\n",
    "        \"If you are speaking to a customer, you probably were transferred to you from the triage agent. \"\n",
    "        \"Use the following routine to support the customer. \\n\"\n",
    "        \"# Routine: \\n\"\n",
    "        \"1. Identify the last question asked by the customer. \\n\"\n",
    "        \"2. Use the search tools to retrieve data about a claim. Do not rely on your own knowledge. \\n\"\n",
    "        \"3. If you cannot answer the question, transfer back to the triage agent. \\n\"\n",
    "    ),\n",
    "    tools=[\n",
    "        search_claims_details_by_policy_no,\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "policy_qa_agent = Agent[UserInfo](\n",
    "    name=\"Policy Q&A Agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are an insurance policy Q&A agent. \"\n",
    "        \"If you are speaking to a customer, you probably were transferred to you from the triage agent. \"\n",
    "        \"Use the following routine to support the customer.\\n\"\n",
    "        \"# Routine: \\n\"\n",
    "        \"1. Identify the last question asked by the customer. \\n\"\n",
    "        \"2. Use the search tools to answer the question about their policy. Do not rely on your own knowledge. \\n\"\n",
    "        \"3. If you cannot answer the question, transfer back to the triage agent. \\n\"\n",
    "    ),\n",
    "    tools=[policy_docs_vector_search],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent[UserInfo](\n",
    "    name=\"Triage agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are a helpful triaging agent. \"\n",
    "        \"You can use your tools to delegate questions to other appropriate agents. \"\n",
    "        \"If the customer does not have anymore questions, wish them a goodbye and a good rest of their day. \"\n",
    "    ),\n",
    "    handoffs=[claims_detail_retrieval_agent, policy_qa_agent],\n",
    "    model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa8f296-d679-4a4d-8291-458a73d1ff2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Experiment with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de1ddde8-c677-4342-8960-1b592106bb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Input some user data as context\n",
    "user_info = UserInfo(cust_id=\"1234\", policy_no=\"12345678\", coversation_id=\"123\", user_id=\"123\")\n",
    "user_input = \"[USER]: I'like to check on my existing claims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5a645d-60e0-4bc9-a4cf-e88dbd2d1069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start a chat span\n",
    "with mlflow.start_span(name=\"insurance_agent\", span_type=\"AGENT\") as span:\n",
    "    print(\"[AGENT] Hello! How may I assist you?\")\n",
    "    while True:\n",
    "        user_input = input(\"[USER]: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"[AGENT]: Bye!\")\n",
    "            break\n",
    "        if not user_input:\n",
    "            continue\n",
    "        try:\n",
    "            result = await Runner.run(\n",
    "                starting_agent=triage_agent, input=user_input, context=user_info\n",
    "            )\n",
    "            print(\"\\n[AGENT]:\", result.final_output)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f906dd9-aac2-4c7e-8676-6dc0a1e409c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = await Runner.run(triage_agent, input=user_input, context=user_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0831dfd-4a86-4a90-a3a2-d41cf1c17356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log, Register and Deploy with Mosaic Agent Framework\n",
    "\n",
    "In order to deploy the chatbot as a “model”, and serve it on Databricks Model Serving, there are a few key steps:\n",
    "\n",
    "- Wrap your agent code in a mlflow.pyfunc.ChatAgent interface as a custom “model”. This schema specification is designed for agent scenarios and is similar to, but not strictly compatible with, the OpenAI ChatCompletion schema.\n",
    "- Log and register the multi-agent system to MLflow and to UC.\n",
    "- Use the `agents.deploy()` function to deploy your chatbot as a REST API endpoint, and instantiate a Review App to begin the evaluation loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca8ca013-6316-4357-80a1-5ff29d44ff68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write the agent chat model to file to prepare for logging the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d922e5b-b82e-4113-bc14-ddb3da9ccfbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile insurance_chat_agent.py\n",
    "from typing import Any, List, Optional, Dict, Generator\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.entities import SpanType\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "import mlflow\n",
    "from uuid import uuid4\n",
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "from unitycatalog.ai.core.databricks import (\n",
    "    DatabricksFunctionClient,\n",
    "    FunctionExecutionResult,\n",
    ")\n",
    "from agents import function_tool, RunContextWrapper\n",
    "from agents import Agent, Runner, set_tracing_disabled\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"{{secrets/databricks_token_qyu/OpenAi}}\"\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "class UserInfo(BaseModel):\n",
    "    cust_id: str | None = None\n",
    "    policy_no: str | None = None\n",
    "    conversation_id: str | None = None\n",
    "    user_id: str | None = None\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def search_claims_details_by_policy_no(wrapper: RunContextWrapper[UserInfo], policy_no: str) -> FunctionExecutionResult:\n",
    "    print(\"[DEBUG]: the 'search_claims_details_by_policy_no' tool was called\")\n",
    "    wrapper.context.policy_no = policy_no\n",
    "    client = DatabricksFunctionClient()\n",
    "    return client.execute_function(\n",
    "        function_name=\"ai.insurance_agent.search_claims_details_by_policy_no\",\n",
    "        parameters={\"input_policy_no\": wrapper.context.policy_no},\n",
    "    )\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def policy_docs_vector_search(query: str) -> FunctionExecutionResult:\n",
    "    print(\"[DEBUG]: the 'policy_docs_vector_search' tool was called\")\n",
    "    client = DatabricksFunctionClient()\n",
    "    return client.execute_function(\n",
    "        function_name=\"ai.insurance_agent.policy_docs_vector_search\",\n",
    "        parameters={\"query\": query},\n",
    "    )\n",
    "\n",
    "set_tracing_disabled(disabled=False)\n",
    "\n",
    "claims_detail_retrieval_agent = Agent[UserInfo](\n",
    "    name=\"Claims Details Retrieval Agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are a claims details retrieval agent. \"\n",
    "        \"If you are speaking to a customer, you probably were transferred to you from the triage agent. \"\n",
    "        \"Use the following routine to support the customer. \\n\"\n",
    "        \"# Routine: \\n\"\n",
    "        \"1. Identify the last question asked by the customer. \\n\"\n",
    "        \"2. Use the search tools to retrieve data about a claim. Do not rely on your own knowledge. \\n\"\n",
    "        \"3. If you cannot answer the question, transfer back to the triage agent. \\n\"\n",
    "    ),\n",
    "    tools=[\n",
    "        search_claims_details_by_policy_no,\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "policy_qa_agent = Agent[UserInfo](\n",
    "    name=\"Policy Q&A Agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are an insurance policy Q&A agent. \"\n",
    "        \"If you are speaking to a customer, you probably were transferred to you from the triage agent. \"\n",
    "        \"Use the following routine to support the customer.\\n\"\n",
    "        \"# Routine: \\n\"\n",
    "        \"1. Identify the last question asked by the customer. \\n\"\n",
    "        \"2. Use the search tools to answer the question about their policy. Do not rely on your own knowledge. \\n\"\n",
    "        \"3. If you cannot answer the question, transfer back to the triage agent. \\n\"\n",
    "    ),\n",
    "    tools=[policy_docs_vector_search],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent[UserInfo](\n",
    "    name=\"Triage agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX}\"\n",
    "        \"You are a helpful triaging agent. \"\n",
    "        \"You can use your tools to delegate questions to other appropriate agents. \"\n",
    "        \"If the customer does not have anymore questions, wish them a goodbye and a good rest of their day. \"\n",
    "    ),\n",
    "    handoffs=[claims_detail_retrieval_agent, policy_qa_agent],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "class InsuranceChatAgent(ChatAgent):\n",
    "    def __init__(self, starting_agent: Agent):\n",
    "        self.starting_agent = starting_agent\n",
    "\n",
    "    def _convert_to_input_text(selfself, messages: List[ChatAgentMessage]) -> str:\n",
    "        \"\"\"Extract the most recent user messages as input text\"\"\"\n",
    "        for message in reversed(messages):\n",
    "            if message.role == \"user\":\n",
    "                return message.content\n",
    "            return \"\"\n",
    "    \n",
    "    def _create_user_context(\n",
    "            self, \n",
    "            context: Optional[ChatContext] = None, \n",
    "            custom_inputs: Optional[Dict[str, Any]] = None\n",
    "        ) -> UserInfo:\n",
    "        \"\"\"Convert MLflow inputs to UserInfo object\"\"\"\n",
    "        user_info = UserInfo()\n",
    "        \n",
    "        if context:\n",
    "            conversation_id = getattr(context, \"conversation_id\", None)\n",
    "            if conversation_id:\n",
    "                user_info.conversation_id = conversation_id\n",
    "                \n",
    "            user_id = getattr(context, \"user_id\", None)\n",
    "            if user_id:\n",
    "                user_info.user_id = user_id\n",
    "            \n",
    "        return user_info\n",
    "\n",
    "    @mlflow.trace(name=\"insurance_chat_agent\", span_type=SpanType.AGENT)\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None\n",
    "    ) -> ChatAgentResponse:\n",
    "        input_text = self._convert_to_input_text(messages)\n",
    "        user_info = self._create_user_context(context, custom_inputs)\n",
    "\n",
    "        # Run the agent use asyncio\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        try:\n",
    "            result = loop.run_until_complete(\n",
    "                Runner.run(\n",
    "                    starting_agent=self.starting_agent,\n",
    "                    input=input_text,\n",
    "                    context=user_info,\n",
    "                )\n",
    "            )\n",
    "        finally:\n",
    "            loop.close()\n",
    "\n",
    "        # Convert the result to ChatAgentResponse format:\n",
    "        return ChatAgentResponse(\n",
    "            messages=[\n",
    "                ChatAgentMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=result.final_output,\n",
    "                    id=str(uuid4())\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @mlflow.trace(name=\"insurance_change_agent_stream\", span_type=SpanType.AGENT)\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None\n",
    "    ) -> Generator[ChatAgentResponse, None, None]:\n",
    "        response = self.predict(messages, context, custom_inputs)\n",
    "\n",
    "        # Yield it as a single chunk\n",
    "        for message in response.messages:\n",
    "            yield ChatAgentChunk(delta=message)\n",
    "\n",
    "AGENT = InsuranceChatAgent(starting_agent=triage_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d193b46-250d-47df-8af5-5bcb5b3585bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load from agent python code and run a couple of validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21268e93-0c55-4235-9d85-0f459bd86c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7c1711f-4a79-44c2-bd12-2b3e8382300c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from insurance_chat_agent import AGENT\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(\n",
    "    scope=\"my_secret_scope\", key=\"OpenAi\"\n",
    ")\n",
    "\n",
    "AGENT.predict(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"hi, id like to check on my existing claims and my policy number: 102070455\",\n",
    "            }\n",
    "        ],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59e17849-87d2-465a-8f18-4a879e4e8293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"does my policy cover towing and labor costs?\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24905bd5-848d-4dbf-9e29-dae26c0bfd1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Logging the model\n",
    "\n",
    "To enable automatic authentication passthrough, since the chatbot needs access to data on Databricks, [specify dependent resources](https://docs.databricks.com/aws/en/generative-ai/agent-framework/log-agent#-specify-resources-for-automatic-authentication-passthrough-system-authentication) using the resources parameter of the MLflow log_model() API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e128b7e-c65e-454d-b28a-ef51ccd420fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksVectorSearchIndex)\n",
    "from unitycatalog.ai.openai.toolkit import UCFunctionToolkit\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(\n",
    "    scope=\"my_secret_scope\", key=\"OpenAi\"\n",
    ")\n",
    "\n",
    "resources = [\n",
    "    DatabricksVectorSearchIndex(\n",
    "        index_name=\"ai.agents.policy_docs_chunked_files_vs_index\"\n",
    "    ),\n",
    "    DatabricksServingEndpoint(endpoint_name=\"databricks-bge-large-en\"),\n",
    "    DatabricksFunction(\n",
    "        function_name=\"ai.insurance_agent.search_claims_details_by_policy_no\"\n",
    "    ),\n",
    "    DatabricksFunction(\n",
    "        function_name=\"ai.insurance_agent.policy_docs_vector_search\"\n",
    "    )\n",
    "]\n",
    "\n",
    "mlflow.set_experiment(f\"/Users/{my_databricks_account}/ML_experiments/insurance_chat_agent\")\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Log the model using the \"models from code\" approach\n",
    "with mlflow.start_run():\n",
    "    logged_model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"insurance_chat_agent\",\n",
    "        python_model=os.path.join(os.getcwd(), \"insurance_chat_agent.py\"),\n",
    "        input_example={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"hi, id like to check on my existing claims?\",\n",
    "                }\n",
    "            ],\n",
    "            \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"},\n",
    "        },\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"openai-agents\",\n",
    "            \"unitycatalog-openai[databricks]==0.2.0\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83984f24-4c0f-4879-ad21-1a780758b436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test logged the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b10ccfde-1b6b-490a-abed-1ff48ac039f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_info.model_uri)\n",
    "\n",
    "# Test it with a sample input\n",
    "response = loaded_model.predict({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims?\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"}\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5e101b-2e0b-42d1-a414-4e7645eb44cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = loaded_model.predict({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims and my policy number is 102070455\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af798e4-830d-4fa3-865a-a138e7ff8604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = loaded_model.predict({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"does my policy cover towing and labor costs?\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80053dc0-eb6b-4f49-93ef-6123641f718b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registered the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74cdc65f-1896-44f2-8d19-c5784b6ff8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "catalog = \"ai\"\n",
    "schema = \"agents\"\n",
    "model_name = \"insurance_chat_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_model_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af92e509-bebf-4538-94ad-1c5ee67e57ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Deploy to an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0729db1f-2725-4e6a-abad-d930c8fb814e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Pre-deployment Env Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00168c1e-68cc-4e0b-8e2a-8f060c6941c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_model_info.run_id}/insurance_chat_agent\",\n",
    "    input_data={\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims?\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"123\"}\n",
    "        },\n",
    "    env_manager=\"uv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11c2146e-f5f3-493f-9ffa-5246e742c146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5edd187b-8cbd-49e0-9412-a8a92d22f183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    environment_vars={\n",
    "        \"OPENAI_API_KEY\": \"{{secrets/my_secret_scope/OpenAI}}\",\n",
    "        \"DATABRICKS_TOKEN\": \"{{secrets/my_secret_scope/databricks_token}}\",\n",
    "    },\n",
    "    tags={\"endpoint_desc\": \"insurance_chat_agent_openai_agent_sdk\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "insurance_chat_agent_driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}